#Set up 
```{r}
library(tidyverse)
library(caret)
library(lubridate)#filtering dates
library(reticulate)
library(recipes)
library(vip)
library(rpart)
library(beepr)

#Read in data
elon <- read.csv("elon_clean.csv")
train <- read.csv("tweet_train.csv")
test <- read.csv("tweet_test.csv")
```

#Parallel processing
```{r}
library(doParallel)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)
```


#Load in encoding model
```{r}
use_condaenv('r-reticulate')

#conda_install(envname  = 'r-reticulate',
#              packages = 'sentence_transformers',
#              pip      = TRUE)

st <- import('sentence_transformers')

model.name <- 'bert-base-uncased'

longformer      <- st$models$Transformer(model.name)
pooling_model   <- st$models$Pooling(longformer$get_word_embedding_dimension())
LFmodel         <- st$SentenceTransformer(modules = list(longformer,pooling_model))
beepr::beep(4)
```


#Process tweet data train
```{r}
#Remove symbols, space, and punctuation
clean_tweets <- function(x) {
            x %>%
                    # Remove URLs
                    str_remove_all(" ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)") %>%
                    # Remove mentions e.g. "@my_account"
                    str_remove_all("@[[:alnum:]_]{4,}") %>%
                    # Remove hash tags
                    str_remove_all("#[[:alnum:]_]+") %>%
                    # Replace "&" character reference with "and"
                    str_replace_all("&amp;", "and") %>%
                    # Remove punctuation, using a standard character class
                    str_remove_all("[[:punct:]]") %>%
                    # Remove "RT: " from beginning of retweets
                    str_remove_all("^RT:? ") %>%
                    # Replace any newline characters with a space
                    str_replace_all("\\\n", " ") %>%
                    # Make everything lowercase
                    str_to_lower() %>%
                    # Remove any trailing whitespace around the text
                    str_trim("both")
        }

#Use function to create column of clean tweets
cleanTweets<- clean_tweets(train$tweets)

#Add column into df
train$cleanTweets <- cleanTweets

#Filter data frame for columns to use
trainClean <- train %>% select(c(sentiment,date,at_dummy,cleanTweets))

#Separate date into day, day #, month, year, hour

day <- word(trainClean$date,1)

date <- word(trainClean$date,3)

month <- word(trainClean$date, 2)

#Grab time of day
time <- word(trainClean$date, 4)

#Lubridate to subset each chunk of time
time <-  lubridate::hms(time)
hour <- time@hour            #Grab Hour 
minutes <- time@minute       #Grab Min

#year <- word(train$date,6) Only 2009, don't need year.  
#unique(year)

#put back into dataframe

trainClean$hour <- hour
trainClean$minutes <- minutes
day_nmr <-  factor(day, levels = c("Mon", "Tue", "Wed", 
                          "Thu", "Fri", "Sat", "Sun"),
            ordered = TRUE)
day_nmr <- as.integer(day_nmr)
trainClean$day <- day_nmr
trainClean$date <- date
trainClean$month <- month

  #Remove date 
train_time_add <- trainClean %>% 
  select(c(sentiment, cleanTweets, day, date, month, hour, minutes, at_dummy))

#Encode data
tweet_encode <- as.data.frame(LFmodel$encode(trainClean$cleanTweets))

#Bind columns 
tweet_encode_bind <- cbind(train_time_add,tweet_encode)
tweet_encode_bind$sentiment <- factor(tweet_encode_bind$sentiment)
  #Drop cleanTweets
tweet_encode_recipeReady <- tweet_encode_bind[,-2]

tweet_encode_recipeReady$day <- as.numeric(tweet_encode_recipeReady$date)

tweet_encode_recipeReady$date <- as.numeric(
  gsub("0", "",tweet_encode_recipeReady$date))

tweet_encode_recipeReady$sentiment <- ifelse(tweet_encode_recipeReady$sentiment == 4, "postive", "negative")

beepr::beep(4)
```

#Clean test data
```{r}
#Remove symbols, space, and punctuation
clean_tweets <- function(x) {
            x %>%
                    # Remove URLs
                    str_remove_all(" ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)") %>%
                    # Remove mentions e.g. "@my_account"
                    str_remove_all("@[[:alnum:]_]{4,}") %>%
                    # Remove hash tags
                    str_remove_all("#[[:alnum:]_]+") %>%
                    # Replace "&" character reference with "and"
                    str_replace_all("&amp;", "and") %>%
                    # Remove punctuation, using a standard character class
                    str_remove_all("[[:punct:]]") %>%
                    # Remove "RT: " from beginning of retweets
                    str_remove_all("^RT:? ") %>%
                    # Replace any newline characters with a space
                    str_replace_all("\\\n", " ") %>%
                    # Make everything lowercase
                    str_to_lower() %>%
                    # Remove any trailing whitespace around the text
                    str_trim("both")
        }

#Use function to create column of clean tweets
cleanTweets<- clean_tweets(test$tweets)

#Add column into df
test$cleanTweets <- cleanTweets

#Filter data frame for columns to use
testClean <- test %>% select(c(sentiment,date,at_dummy,cleanTweets))

#Separate date into day, day #, month, year, hour

day <- word(testClean$date,1)

date <- word(testClean$date,3)

month <- word(testClean$date, 2)

#Grab time of day
time <- word(testClean$date, 4)

#Lubridate to subset each chunk of time
time <-  lubridate::hms(time)
hour <- time@hour            #Grab Hour 
minutes <- time@minute       #Grab Min

#year <- word(train$date,6) Only 2009, don't need year.  
#unique(year)

#put back into dataframe

testClean$hour <- hour
testClean$minutes <- minutes
day_nmr <-  factor(day, levels = c("Mon", "Tue", "Wed", 
                          "Thu", "Fri", "Sat", "Sun"),
            ordered = TRUE)
day_nmr <- as.integer(day_nmr)
testClean$day <- day_nmr
testClean$date <- date
testClean$month <- month

  #Remove date 
test_time_add <- testClean %>% 
  select(c(sentiment, cleanTweets, day, date, month, hour, minutes, at_dummy))

#Encode data 
tweet_encode_test <- as.data.frame(LFmodel$encode(testClean$cleanTweets))

#Bind columns 
tweet_encode_bind <- cbind(test_time_add,tweet_encode_test)
tweet_encode_bind$sentiment <- factor(tweet_encode_bind$sentiment)
  #Drop cleanTweets
test_encode <- tweet_encode_bind[,-2]

test_encode$date <- as.numeric(
  gsub("0", "",test_encode$date))

test_encode$sentiment <- ifelse(test_encode$sentiment == 4, "postive", "negative")
beepr::beep(4)

```


#Recipe and folds 
```{r}
blueprint_tweet_sentiment <- recipe(x = tweet_encode_recipeReady,
                                    vars = colnames(tweet_encode_recipeReady), 
                                    roles = c('outcome', rep('predictor',774))) %>% 
  step_dummy('month', one_hot = T) %>% 
  step_harmonic('day',frequency=1,cycle_size=7, role='predictor') %>%
  step_harmonic('date',frequency=1,cycle_size=31,role='predictor') %>%
  step_harmonic('hour',frequency=1,cycle_size=24,role='predictor') %>%
  step_normalize(paste0('V',1:768)) %>%
  step_normalize(c('day_sin_1','day_cos_1',
                   'date_sin_1','date_cos_1',
                   'hour_sin_1','hour_cos_1')) %>%
  step_num2factor(tweet_encode_recipeReady$sentinment,
                  levels = c('negative', 'positive')) %>% 
  step_normalize(all_numeric_predictors())

#Create fold 
folds = cut(seq(1, nrow(tweet_encode_recipeReady)), breaks = 10, labels = F)

#Index list
index <-vector('list', 10)

for (i in 1:10){
  index[[i]] <- which(folds != i)
}



cv <- trainControl(method = "cv",
                   index  = index,
                   classProbs      = TRUE)


#Hyperparameter grid 
grid <- data.frame(alpha = 0 , 
               lambda = seq(0,3, 0.01))

beepr::beep(4)
View(blueprint_tweet_sentiment %>% prep() %>% summary)

str(blueprint_tweet_sentiment$term_info)
```

#GLM
```{r}
set.seed(0294875)
model_glmnet <- caret::train(blueprint_tweet_sentiment, 
                             data = tweet_encode_recipeReady,
                             method= "glmnet",
                             trainControl = cv,
                             family = 'binomial',
                             tuneGrid = grid)

prediction <- predict(model_glmnet, test_encode, type = 'prob')
prediction

#Best fit 
model_glmnet$results
model_glmnet$bestTune

vip(model_glmnet)

plot(model_glmnet)

saveRDS(model_glmnet,"./model_glmnet")

beepr::beep(4)
```
#Decision tree model 
```{r}
set.seed(0294875)
cv_tree <- trainControl(method = "cv",
                   index  = index,
                   classProbs = F)

grid_tree <- data.frame(cp=seq(0,0.02,.001)) #Hyper parameter: complexity parameter




model_tree <- caret::train(blueprint_tweet_sentiment,
                             data      = tweet_encode_recipeReady,
                             method    = 'rpart',
                             tuneGrid  = grid_tree,
                             trControl = cv_tree,
                             control   = list(minsplit=20,
                                             minbucket = 2,
                                             maxdepth = 30))
model_tree$results
model_tree$bestTune

predict_tree <- predict(model_tree, test_encode)
predict_tree
beepr::beep(4)

plot(model_tree)


saveRDS(model_tree,"./model_tree")
```

#Neural network 
```{r}
model_tree <- caret::train(blueprint_tweet_sentiment,
                             data      = tweet_encode_recipeReady,
                             method    = 'rpart',
                             tuneGrid  = grid_tree,
                             trControl = cv_tree,
                             control   = list(minsplit=20,
                                             minbucket = 2,
                                             maxdepth = 30))
```



